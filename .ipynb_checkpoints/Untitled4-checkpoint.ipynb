{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8520e88-a94f-43c3-abd6-f8c566abd096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database Fundamentals</th>\n",
       "      <th>Computer Architecture</th>\n",
       "      <th>Distributed Computing Systems</th>\n",
       "      <th>Cyber Security</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Programming Skills</th>\n",
       "      <th>Project Management</th>\n",
       "      <th>Computer Forensics Fundamentals</th>\n",
       "      <th>Technical Communication</th>\n",
       "      <th>AI ML</th>\n",
       "      <th>Software Engineering</th>\n",
       "      <th>Business Analysis</th>\n",
       "      <th>Communication skills</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Troubleshooting skills</th>\n",
       "      <th>Graphics Designing</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Professional</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Database Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Professional</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Database Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Professional</td>\n",
       "      <td>Beginner</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Database Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Professional</td>\n",
       "      <td>Average</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Database Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Professional</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Not Interested</td>\n",
       "      <td>Database Administrator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Database Fundamentals Computer Architecture Distributed Computing Systems  \\\n",
       "0          Professional        Not Interested                Not Interested   \n",
       "1          Professional                  Poor                Not Interested   \n",
       "2          Professional              Beginner                Not Interested   \n",
       "3          Professional               Average                Not Interested   \n",
       "4          Professional          Intermediate                Not Interested   \n",
       "\n",
       "   Cyber Security      Networking Software Development Programming Skills  \\\n",
       "0  Not Interested  Not Interested       Not Interested     Not Interested   \n",
       "1  Not Interested  Not Interested       Not Interested     Not Interested   \n",
       "2  Not Interested  Not Interested       Not Interested     Not Interested   \n",
       "3  Not Interested  Not Interested       Not Interested     Not Interested   \n",
       "4  Not Interested  Not Interested       Not Interested     Not Interested   \n",
       "\n",
       "  Project Management Computer Forensics Fundamentals Technical Communication  \\\n",
       "0     Not Interested                  Not Interested          Not Interested   \n",
       "1     Not Interested                  Not Interested          Not Interested   \n",
       "2     Not Interested                  Not Interested          Not Interested   \n",
       "3     Not Interested                  Not Interested          Not Interested   \n",
       "4     Not Interested                  Not Interested          Not Interested   \n",
       "\n",
       "            AI ML Software Engineering Business Analysis Communication skills  \\\n",
       "0  Not Interested       Not Interested    Not Interested       Not Interested   \n",
       "1  Not Interested       Not Interested    Not Interested       Not Interested   \n",
       "2  Not Interested       Not Interested    Not Interested       Not Interested   \n",
       "3  Not Interested       Not Interested    Not Interested       Not Interested   \n",
       "4  Not Interested       Not Interested    Not Interested       Not Interested   \n",
       "\n",
       "     Data Science Troubleshooting skills Graphics Designing  \\\n",
       "0  Not Interested         Not Interested     Not Interested   \n",
       "1  Not Interested         Not Interested     Not Interested   \n",
       "2  Not Interested         Not Interested     Not Interested   \n",
       "3  Not Interested         Not Interested     Not Interested   \n",
       "4  Not Interested         Not Interested     Not Interested   \n",
       "\n",
       "                     Role  \n",
       "0  Database Administrator  \n",
       "1  Database Administrator  \n",
       "2  Database Administrator  \n",
       "3  Database Administrator  \n",
       "4  Database Administrator  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"career (1).csv\", dtype=str)\n",
    "df = df1.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6f210d2-a956-40b6-9c33-c0a9cc885c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Fundamentals= ['Professional' 'Not Interested' 'Poor' 'Beginner' 'Average'\n",
      " 'Intermediate' 'Excellent']\n",
      "Computer Architecture= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Leadership_Experience= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Cyber Security\t= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Networking= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Software Development= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Programming Skills= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Project Management= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Computer Forensics Fundamentals= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Technical Communication= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "AI ML= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Software Engineering= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Business Analysis= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Communication skills= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Data Science= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Troubleshooting skills= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " 'Professional']\n",
      "Graphics Designing= ['Not Interested' 'Poor' 'Beginner' 'Average' 'Intermediate' 'Excellent'\n",
      " nan 'Professional']\n",
      "Role= ['Database Administrator' 'Hardware Engineer'\n",
      " 'Application Support Engineer' 'Cyber Security Specialist'\n",
      " 'Networking Engineer' 'Software Developer' 'API Specialist'\n",
      " 'Project Manager' 'Information Security Specialist' 'Technical Writer'\n",
      " 'AI ML Specialist' 'Software tester' 'Business Analyst'\n",
      " 'Customer Service Executive' 'Data Scientist' 'Helpdesk Engineer'\n",
      " 'Graphics Designer']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=df['Database Fundamentals'].unique().astype(str)\n",
    "y=df['Computer Architecture'].unique()\n",
    "z=df['Distributed Computing Systems'].unique()\n",
    "f=df['Cyber Security'].unique()\n",
    "c=df['Networking'].unique()\n",
    "a=df['Software Development'].unique()\n",
    "b=df['Programming Skills'].unique()\n",
    "d=df['Project Management'].unique()\n",
    "e=df['Computer Forensics Fundamentals'].unique()\n",
    "g=df['Technical Communication'].unique()\n",
    "h=df['AI ML'].unique()\n",
    "i=df['Software Engineering'].unique()\n",
    "j=df['Business Analysis'].unique()\n",
    "k=df['Communication skills'].unique()\n",
    "l=df['Data Science'].unique()\n",
    "m=df['Troubleshooting skills'].unique()\n",
    "n=df['Graphics Designing'].unique()\n",
    "o=df['Role'].unique()\n",
    "\n",
    "print(\"Database Fundamentals=\",x)\n",
    "print(\"Computer Architecture=\",y)\n",
    "print(\"Leadership_Experience=\",z)\n",
    "print(\"Cyber Security\t=\",f)\n",
    "print(\"Networking=\",c)\n",
    "print(\"Software Development=\",a)\n",
    "print(\"Programming Skills=\",b)\n",
    "print(\"Project Management=\",d)\n",
    "print(\"Computer Forensics Fundamentals=\",e)\n",
    "print(\"Technical Communication=\",g)\n",
    "print(\"AI ML=\",h)\n",
    "print(\"Software Engineering=\",i)\n",
    "print(\"Business Analysis=\",j)\n",
    "print(\"Communication skills=\",k)\n",
    "print(\"Data Science=\",l)\n",
    "print(\"Troubleshooting skills=\",m)\n",
    "print(\"Graphics Designing=\",n)\n",
    "print(\"Role=\",o)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341a7a5b-e729-43dc-b57d-104ea5a7b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Database Fundamentals'] = label_encoder.fit_transform(df['Database Fundamentals'])\n",
    "df['Computer Architecture'] = label_encoder.fit_transform(df['Computer Architecture'])\n",
    "df['Distributed Computing Systems'] = label_encoder.fit_transform(df['Distributed Computing Systems'])\n",
    "df['Cyber Security'] = label_encoder.fit_transform(df['Cyber Security'])\n",
    "df['Networking'] = label_encoder.fit_transform(df['Networking'])\n",
    "df['Software Development'] = label_encoder.fit_transform(df['Software Development'])\n",
    "df['Programming Skills'] = label_encoder.fit_transform(df['Programming Skills'])\n",
    "df['Project Management'] = label_encoder.fit_transform(df['Project Management'])\n",
    "df['Computer Forensics Fundamentals'] = label_encoder.fit_transform(df['Computer Forensics Fundamentals'])\n",
    "df['Technical Communication'] = label_encoder.fit_transform(df['Technical Communication'])\n",
    "df['AI ML'] = label_encoder.fit_transform(df['AI ML'])\n",
    "df['Software Engineering'] = label_encoder.fit_transform(df['Software Engineering'])\n",
    "df['Business Analysis'] = label_encoder.fit_transform(df['Business Analysis'])\n",
    "df['Communication skills'] = label_encoder.fit_transform(df['Communication skills'])\n",
    "df['Data Science'] = label_encoder.fit_transform(df['Data Science'])\n",
    "df['Troubleshooting skills'] = label_encoder.fit_transform(df['Troubleshooting skills'])\n",
    "df['Graphics Designing'] = label_encoder.fit_transform(df['Graphics Designing'])\n",
    "df['Role'] = label_encoder.fit_transform(df['Role'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee82bf12-a828-4356-803b-0fe2e9d164b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  9,  2,  5, 12, 14,  1, 13, 11, 16,  0, 15,  3,  4,  6, 10,  8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Role'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02842a40-7dea-4ba6-896c-229fd90efad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7     540\n",
       "16    540\n",
       "10    540\n",
       "6     540\n",
       "4     540\n",
       "3     540\n",
       "15    540\n",
       "0     540\n",
       "11    540\n",
       "9     540\n",
       "13    540\n",
       "1     540\n",
       "14    540\n",
       "12    540\n",
       "5     540\n",
       "2     540\n",
       "8     539\n",
       "Name: Role, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c19efda-9e36-40f9-acc3-67fb286ecdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Database Fundamentals</th>\n",
       "      <th>Computer Architecture</th>\n",
       "      <th>Distributed Computing Systems</th>\n",
       "      <th>Cyber Security</th>\n",
       "      <th>Networking</th>\n",
       "      <th>Software Development</th>\n",
       "      <th>Programming Skills</th>\n",
       "      <th>Project Management</th>\n",
       "      <th>Computer Forensics Fundamentals</th>\n",
       "      <th>Technical Communication</th>\n",
       "      <th>AI ML</th>\n",
       "      <th>Software Engineering</th>\n",
       "      <th>Business Analysis</th>\n",
       "      <th>Communication skills</th>\n",
       "      <th>Data Science</th>\n",
       "      <th>Troubleshooting skills</th>\n",
       "      <th>Graphics Designing</th>\n",
       "      <th>Role</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "      <td>9179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.705959</td>\n",
       "      <td>2.706068</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850403</td>\n",
       "      <td>1.850626</td>\n",
       "      <td>4.899513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Database Fundamentals  Computer Architecture  \\\n",
       "count            9179.000000            9179.000000   \n",
       "mean                2.705959               2.705959   \n",
       "std                 1.850403               1.850403   \n",
       "min                 0.000000               0.000000   \n",
       "25%                 1.000000               1.000000   \n",
       "50%                 3.000000               3.000000   \n",
       "75%                 4.000000               4.000000   \n",
       "max                 6.000000               6.000000   \n",
       "\n",
       "       Distributed Computing Systems  Cyber Security   Networking  \\\n",
       "count                    9179.000000     9179.000000  9179.000000   \n",
       "mean                        2.705959        2.705959     2.705959   \n",
       "std                         1.850403        1.850403     1.850403   \n",
       "min                         0.000000        0.000000     0.000000   \n",
       "25%                         1.000000        1.000000     1.000000   \n",
       "50%                         3.000000        3.000000     3.000000   \n",
       "75%                         4.000000        4.000000     4.000000   \n",
       "max                         6.000000        6.000000     6.000000   \n",
       "\n",
       "       Software Development  Programming Skills  Project Management  \\\n",
       "count           9179.000000         9179.000000         9179.000000   \n",
       "mean               2.705959            2.705959            2.705959   \n",
       "std                1.850403            1.850403            1.850403   \n",
       "min                0.000000            0.000000            0.000000   \n",
       "25%                1.000000            1.000000            1.000000   \n",
       "50%                3.000000            3.000000            3.000000   \n",
       "75%                4.000000            4.000000            4.000000   \n",
       "max                6.000000            6.000000            6.000000   \n",
       "\n",
       "       Computer Forensics Fundamentals  Technical Communication        AI ML  \\\n",
       "count                      9179.000000              9179.000000  9179.000000   \n",
       "mean                          2.705959                 2.705959     2.705959   \n",
       "std                           1.850403                 1.850403     1.850403   \n",
       "min                           0.000000                 0.000000     0.000000   \n",
       "25%                           1.000000                 1.000000     1.000000   \n",
       "50%                           3.000000                 3.000000     3.000000   \n",
       "75%                           4.000000                 4.000000     4.000000   \n",
       "max                           6.000000                 6.000000     6.000000   \n",
       "\n",
       "       Software Engineering  Business Analysis  Communication skills  \\\n",
       "count           9179.000000        9179.000000           9179.000000   \n",
       "mean               2.705959           2.705959              2.705959   \n",
       "std                1.850403           1.850403              1.850403   \n",
       "min                0.000000           0.000000              0.000000   \n",
       "25%                1.000000           1.000000              1.000000   \n",
       "50%                3.000000           3.000000              3.000000   \n",
       "75%                4.000000           4.000000              4.000000   \n",
       "max                6.000000           6.000000              6.000000   \n",
       "\n",
       "       Data Science  Troubleshooting skills  Graphics Designing         Role  \n",
       "count   9179.000000             9179.000000         9179.000000  9179.000000  \n",
       "mean       2.705959                2.705959            2.706068     8.000000  \n",
       "std        1.850403                1.850403            1.850626     4.899513  \n",
       "min        0.000000                0.000000            0.000000     0.000000  \n",
       "25%        1.000000                1.000000            1.000000     4.000000  \n",
       "50%        3.000000                3.000000            3.000000     8.000000  \n",
       "75%        4.000000                4.000000            4.000000    12.000000  \n",
       "max        6.000000                6.000000            7.000000    16.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c0c4241-bc90-4374-956a-62d7e4567352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "X = df.drop('Role', axis=1)\n",
    "y = df['Role']\n",
    "\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dc7df40-3779-4b6f-a3b9-ba3bbec64f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.8169934640522876\n",
      "F1-Score: 0.8150142688882174\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.7312999273783588\n",
      "F1-Score: 0.716785782487353\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8445896877269427\n",
      "F1-Score: 0.8437374378632817\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.7396514161220044\n",
      "F1-Score: 0.7481002090173139\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.7490922294843864\n",
      "F1-Score: 0.7519428053325532\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.7135076252723311\n",
      "F1-Score: 0.7192574479049669\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n",
      "Accuracy: 0.6601307189542484\n",
      "F1-Score: 0.6477403279552011\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.8489469862018881\n",
      "F1-Score: 0.8496585434735127\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.9030501089324618\n",
      "F1-Score: 0.9031502250401762\n",
      "==================================================\n",
      "Logistic Regression - Cross-Validation Accuracy: 0.9998910675381264\n",
      "==================================================\n",
      "Support Vector Classifier - Cross-Validation Accuracy: 0.9452069716775598\n",
      "==================================================\n",
      "Random Forest Classifier - Cross-Validation Accuracy: 0.9998910675381264\n",
      "==================================================\n",
      "K Nearest Neighbors - Cross-Validation Accuracy: 0.7672113289760348\n",
      "==================================================\n",
      "Decision Tree Classifier - Cross-Validation Accuracy: 0.6470588235294118\n",
      "==================================================\n",
      "Gaussian Naive Bayes - Cross-Validation Accuracy: 1.0\n",
      "==================================================\n",
      "AdaBoost Classifier - Cross-Validation Accuracy: 0.8235294117647058\n",
      "==================================================\n",
      "Gradient Boosting Classifier - Cross-Validation Accuracy: 0.9998910675381264\n",
      "==================================================\n",
      "XGBoost Classifier - Cross-Validation Accuracy: 0.9998910675381264\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# افترض أن X_resampled و y_resampled هي بياناتك المعاد توازنها\n",
    "# X_resampled, y_resampled = ...\n",
    "\n",
    "# 1. تقسيم البيانات مع زيادة حجم مجموعة الاختبار\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=150)\n",
    "\n",
    "# 2. تقليل الأبعاد باستخدام PCA\n",
    "pca = PCA(n_components=10)  # اختيار 10 مكونات رئيسية\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# 3. اختيار أفضل الميزات باستخدام SelectKBest\n",
    "selector = SelectKBest(f_classif, k=10)  # اختيار أفضل 10 ميزات\n",
    "X_train_selected = selector.fit_transform(X_train_pca, y_train)\n",
    "X_test_selected = selector.transform(X_test_pca)\n",
    "\n",
    "# 4. تعريف النماذج مع ضبط المعلمات لتقليل التعقيد\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(C=0.1, random_state=150),\n",
    "    \"Support Vector Classifier\": SVC(C=0.1, probability=True, random_state=150),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(\n",
    "        max_depth=10, min_samples_split=10, n_estimators=50, random_state=150\n",
    "    ),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(\n",
    "        max_depth=10, min_samples_split=10, random_state=150\n",
    "    ),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(n_estimators=50, random_state=150),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(\n",
    "        max_depth=5, n_estimators=50, random_state=150\n",
    "    ),\n",
    "    \"XGBoost Classifier\": XGBClassifier(\n",
    "        max_depth=5, n_estimators=50, use_label_encoder=False, eval_metric='mlogloss', random_state=150\n",
    "    ),\n",
    "}\n",
    "\n",
    "# 5. تدريب وتقييم النماذج\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # تدريب النموذج\n",
    "    model.fit(X_train_selected, y_train)\n",
    "    \n",
    "    # التنبؤ على مجموعة الاختبار\n",
    "    y_pred = model.predict(X_test_selected)\n",
    "    \n",
    "    # حساب الدقة و F1-Score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    # حفظ النتائج\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"F1-Score\": f1,\n",
    "    }\n",
    "\n",
    "# 6. عرض النتائج\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']}\")\n",
    "    print(f\"F1-Score: {metrics['F1-Score']}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "# 7. استخدام Cross-Validation للتحقق من الأداء\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_resampled, y_resampled, cv=5, scoring='accuracy')\n",
    "    print(f\"{name} - Cross-Validation Accuracy: {scores.mean()}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0748705e-8c99-435c-9e7f-73db6cd36f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6044016-ae58-492a-8363-b54f5d355daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6426, 17)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed0bca67-f8d5-40b4-ab61-2f37f7446971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac1580d-27c5-4324-af37-ce0ff034330a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6426, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28dd55a7-f3ae-423e-9f95-a0e34a755175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 0}\n",
      "Accuracy:  0.9996368917937546\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       163\n",
      "           1       1.00      1.00      1.00       146\n",
      "           2       1.00      1.00      1.00       171\n",
      "           3       1.00      1.00      1.00       179\n",
      "           4       1.00      1.00      1.00       156\n",
      "           5       1.00      1.00      1.00       167\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       1.00      1.00      1.00       160\n",
      "           8       0.99      1.00      1.00       159\n",
      "           9       1.00      1.00      1.00       142\n",
      "          10       1.00      0.99      1.00       157\n",
      "          11       1.00      1.00      1.00       162\n",
      "          12       1.00      1.00      1.00       170\n",
      "          13       1.00      1.00      1.00       168\n",
      "          14       1.00      1.00      1.00       162\n",
      "          15       1.00      1.00      1.00       152\n",
      "          16       1.00      1.00      1.00       184\n",
      "\n",
      "    accuracy                           1.00      2754\n",
      "   macro avg       1.00      1.00      1.00      2754\n",
      "weighted avg       1.00      1.00      1.00      2754\n",
      "\n",
      "Confusion Matrix: \n",
      " [[163   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 146   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 171   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 179   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 156   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 167   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 156   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 160   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 159   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 142   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0 156   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 162   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 168   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 162   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 152   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 184]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE  # للتعامل مع البيانات غير المتوازنة\n",
    "\n",
    "# 1. تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=150)\n",
    "\n",
    "# 2. تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. التعامل مع البيانات غير المتوازنة (إذا كانت موجودة)\n",
    "smote = SMOTE(random_state=150)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. ضبط معلمات النموذج باستخدام GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [0, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "model = XGBClassifier(random_state=150, use_label_encoder=False, eval_metric='mlogloss')\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# أفضل معلمات\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 5. تدريب النموذج بأفضل المعلمات\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# 6. التنبؤ والتقييم\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d3f9457-41df-46a3-83d9-c6fef1c28ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy:  0.6368606990756358\n",
      "Accuracy:  0.6379811183732752\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       163\n",
      "           1       1.00      1.00      1.00       146\n",
      "           2       0.11      0.14      0.12       171\n",
      "           3       0.14      0.42      0.21       179\n",
      "           4       1.00      1.00      1.00       156\n",
      "           5       1.00      1.00      1.00       167\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       1.00      1.00      1.00       160\n",
      "           8       0.13      0.31      0.19       159\n",
      "           9       0.00      0.00      0.00       142\n",
      "          10       0.00      0.00      0.00       157\n",
      "          11       1.00      1.00      1.00       162\n",
      "          12       0.00      0.00      0.00       170\n",
      "          13       0.00      0.00      0.00       168\n",
      "          14       1.00      1.00      1.00       162\n",
      "          15       1.00      1.00      1.00       152\n",
      "          16       1.00      1.00      1.00       184\n",
      "\n",
      "    accuracy                           0.64      2754\n",
      "   macro avg       0.61      0.64      0.62      2754\n",
      "weighted avg       0.61      0.64      0.62      2754\n",
      "\n",
      "Confusion Matrix: \n",
      " [[163   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 146   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  24  81   0   0   0   0  66   0   0   0   0   0   0   0   0]\n",
      " [  0   0  40  75   0   0   0   0  64   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 156   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 167   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 156   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 160   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  33  76   0   0   0   0  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0  27  65   0   0   0   0  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0  40  74   0   0   0   0  43   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 162   0   0   0   0   0]\n",
      " [  0   0  31  89   0   0   0   0  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0  33  79   0   0   0   0  56   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 162   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 152   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 184]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# 1. تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=150)\n",
    "\n",
    "# 2. تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. موازنة البيانات (إذا كانت غير متوازنة)\n",
    "smote = SMOTE(random_state=150)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. اختيار أفضل الميزات\n",
    "selector = SelectKBest(f_classif, k=10)  # اختيار أفضل 10 ميزات\n",
    "X_train_selected = selector.fit_transform(X_train_resampled, y_train_resampled)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# 5. بناء النموذج\n",
    "model = XGBClassifier(\n",
    "    max_depth=3,           # عمق الأشجار = 3\n",
    "    n_estimators=100,      # عدد الأشجار = 100\n",
    "    learning_rate=0.05,    # معدل التعلم = 0.05\n",
    "    reg_alpha=0.1,         # تنظيم L1\n",
    "    reg_lambda=0.1,        # تنظيم L2\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=150\n",
    ")\n",
    "\n",
    "# 6. التحقق المتقاطع\n",
    "scores = cross_val_score(model, X_train_selected, y_train_resampled, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy: \", scores.mean())\n",
    "\n",
    "# 7. تدريب النموذج\n",
    "model.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# 8. التنبؤ والتقييم\n",
    "y_pred = model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e06b019-3ab7-401e-8eb9-2a5ce57d54df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_scaled: (6425, 5)\n",
      "Shape of y_train: (6425,)\n",
      "Shape of X_test_scaled: (2754, 5)\n",
      "Shape of y_test: (2754,)\n",
      "Accuracy:  0.3253449527959332\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.08      0.06       163\n",
      "           1       1.00      1.00      1.00       146\n",
      "           2       0.00      0.00      0.00       171\n",
      "           3       0.02      0.01      0.01       179\n",
      "           4       1.00      1.00      1.00       156\n",
      "           5       0.10      0.04      0.05       167\n",
      "           6       1.00      1.00      1.00       156\n",
      "           7       0.04      0.01      0.01       160\n",
      "           8       0.09      0.15      0.11       159\n",
      "           9       1.00      1.00      1.00       142\n",
      "          10       0.08      0.16      0.10       157\n",
      "          11       0.02      0.01      0.01       162\n",
      "          12       0.08      0.17      0.11       170\n",
      "          13       0.07      0.11      0.08       168\n",
      "          14       0.06      0.01      0.02       162\n",
      "          15       1.00      1.00      1.00       152\n",
      "          16       0.09      0.13      0.11       184\n",
      "\n",
      "    accuracy                           0.33      2754\n",
      "   macro avg       0.33      0.34      0.33      2754\n",
      "weighted avg       0.31      0.33      0.31      2754\n",
      "\n",
      "Confusion Matrix:  [[ 13   0   1   6   0   5   0   2  23   0  31   3  28  25   1   0  25]\n",
      " [  0 146   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 29   0   0   5   0   3   0   4  17   0  35   2  25  22   4   0  25]\n",
      " [ 30   0   2   1   0   9   0   2  20   0  32   5  31  21   2   0  24]\n",
      " [  0   0   0   0 156   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 28   0   1   0   0   6   0   1  21   0  22   8  30  23   3   0  24]\n",
      " [  0   0   0   0   0   0 156   0   0   0   0   0   0   0   0   0   0]\n",
      " [ 24   0   2   2   0   3   0   1  21   0  24   3  33  21   4   0  22]\n",
      " [ 22   0   1   5   0   4   0   3  24   0  25   1  21  27   3   0  23]\n",
      " [  0   0   0   0   0   0   0   0   0 142   0   0   0   0   0   0   0]\n",
      " [ 13   0   0   6   0   4   0   3  22   0  25   5  29  19   5   0  26]\n",
      " [ 21   0   0   8   0   4   0   0  33   0  27   1  26  20   2   0  20]\n",
      " [ 20   0   0   5   0   6   0   3  21   0  29   5  29  28   5   0  19]\n",
      " [ 27   0   1   6   0   5   0   2  26   0  26   6  32  18   4   0  15]\n",
      " [ 20   0   2   4   0   6   0   1  15   0  25   6  38  22   2   0  21]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 152   0]\n",
      " [ 32   0   2   1   0   5   0   1  30   0  26   5  31  26   1   0  24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# التحقق من تطابق عدد العينات\n",
    "print(\"Shape of X_train_scaled:\", X_train_selected.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test_scaled:\", X_test_selected.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n",
    "\n",
    "# بناء النموذج\n",
    "model = XGBClassifier( max_depth=5, n_estimators=50, use_label_encoder=False, eval_metric='mlogloss', random_state=150)\n",
    "\n",
    "# تدريب النموذج على بيانات التدريب\n",
    "model.fit(X_train_selected, y_train)  # تم التصحيح هنا: استخدام X_train_scaled بدلاً من X_test_selected\n",
    "\n",
    "# التنبؤ على بيانات الاختبار\n",
    "y_pred = model.predict(X_test_selected)  # تم التصحيح هنا: استخدام X_test_scaled\n",
    "\n",
    "# تقييم النموذج\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10fa8923-f946-4781-93e2-92e4875692ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy:  0.8257471497771242\n",
      "Accuracy:  0.8257080610021786\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.72      0.70       163\n",
      "           1       0.71      0.72      0.71       143\n",
      "           2       0.89      0.95      0.92       170\n",
      "           3       0.84      0.82      0.83       179\n",
      "           4       0.85      0.87      0.86       147\n",
      "           5       0.89      0.85      0.87       167\n",
      "           6       0.70      0.84      0.76       153\n",
      "           7       0.91      0.88      0.90       160\n",
      "           8       0.59      0.62      0.60       158\n",
      "           9       0.83      0.86      0.84       142\n",
      "          10       0.60      0.49      0.54       162\n",
      "          11       0.92      0.96      0.94       169\n",
      "          12       0.88      0.87      0.87       170\n",
      "          13       0.94      0.92      0.93       173\n",
      "          14       0.90      0.82      0.86       162\n",
      "          15       0.93      0.94      0.93       160\n",
      "          16       0.93      0.88      0.91       176\n",
      "\n",
      "    accuracy                           0.83      2754\n",
      "   macro avg       0.82      0.82      0.82      2754\n",
      "weighted avg       0.83      0.83      0.82      2754\n",
      "\n",
      "Confusion Matrix: \n",
      " [[117   2   3  12   1   3   6   3   0   6   1   1   1   2   1   2   2]\n",
      " [  2 103   3   2   3   6   7   3   1   2   1   1   1   2   2   2   2]\n",
      " [  2   0 161   1   0   0   2   0   0   0   0   1   0   0   0   3   0]\n",
      " [ 20   2   3 147   2   1   0   1   0   0   0   2   1   0   0   0   0]\n",
      " [  0   5   1   1 128   2   5   1   0   1   0   0   3   0   0   0   0]\n",
      " [  0   5   1   7   0 142   3   0   1   0   0   0   6   1   0   1   0]\n",
      " [  5   1   1   1   5   2 128   0   1   1   1   1   0   2   2   0   2]\n",
      " [  2   4   1   0   0   1   8 141   1   1   0   0   0   0   0   1   0]\n",
      " [  1   3   1   2   1   0   2   0  98   3  44   1   0   1   0   1   0]\n",
      " [  1   6   1   0   0   0   1   0   0 122   1   2   3   0   2   1   2]\n",
      " [  2   1   1   3   2   2   1   1  62   3  79   0   2   0   2   0   1]\n",
      " [  0   0   0   0   0   0   5   1   0   0   0 162   0   0   0   1   0]\n",
      " [  5   4   1   0   3   1   3   0   0   0   0   3 148   0   1   0   1]\n",
      " [  2   1   0   0   0   0   5   0   1   1   0   0   0 159   4   0   0]\n",
      " [ 10   6   1   0   2   0   3   3   0   1   0   1   1   0 133   0   1]\n",
      " [  0   1   0   0   2   0   0   1   0   0   0   1   3   0   1 151   0]\n",
      " [  0   2   1   0   1   0   3   0   2   6   4   0   0   2   0   0 155]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=150)\n",
    "\n",
    "# 2. تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. موازنة البيانات (إذا كانت غير متوازنة)\n",
    "smote = SMOTE(random_state=150)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# 4. تطبيق PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_resampled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# 5. تطبيق SelectKBest\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train_pca, y_train_resampled)\n",
    "X_test_selected = selector.transform(X_test_pca)\n",
    "\n",
    "# 6. بناء النموذج\n",
    "model = XGBClassifier(\n",
    "    max_depth=5,           # عمق الأشجار = 5\n",
    "    n_estimators=200,      # عدد الأشجار = 200\n",
    "    learning_rate=0.01,    # معدل التعلم = 0.01\n",
    "    reg_alpha=0.1,         # تنظيم L1\n",
    "    reg_lambda=0.1,        # تنظيم L2\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=150\n",
    ")\n",
    "\n",
    "# 7. التحقق المتقاطع\n",
    "scores = cross_val_score(model, X_train_selected, y_train_resampled, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy: \", scores.mean())\n",
    "\n",
    "# 8. تدريب النموذج\n",
    "model.fit(X_train_selected, y_train_resampled)\n",
    "\n",
    "# 9. التنبؤ والتقييم\n",
    "y_pred = model.predict(X_test_selected)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78beb7b4-ea34-43e8-a217-ce9b21795c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8779956427015251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=150)\n",
    "\n",
    "# تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# تطبيق PCA\n",
    "pca = PCA(n_components=10)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# تطبيق SelectKBest\n",
    "selector = SelectKBest(f_classif, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train_pca, y_train)\n",
    "X_test_selected = selector.transform(X_test_pca)\n",
    "\n",
    "# تدريب النموذج\n",
    "model = XGBClassifier(max_depth=5, n_estimators=50, use_label_encoder=False, eval_metric='mlogloss', random_state=150)\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# التنبؤ\n",
    "y_pred = model.predict(X_test_selected)\n",
    "\n",
    "# تقييم النموذج\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "092311ea-c8e2-4bff-b06e-2424a172f20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "النموذج الأول (باستخدام البيانات المحجمة فقط):\n",
      "Accuracy:  0.9996368917937546\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       163\n",
      "           1       1.00      1.00      1.00       143\n",
      "           2       1.00      1.00      1.00       170\n",
      "           3       1.00      1.00      1.00       179\n",
      "           4       1.00      1.00      1.00       147\n",
      "           5       1.00      1.00      1.00       167\n",
      "           6       1.00      1.00      1.00       153\n",
      "           7       1.00      1.00      1.00       160\n",
      "           8       0.99      1.00      1.00       158\n",
      "           9       1.00      1.00      1.00       142\n",
      "          10       1.00      0.99      1.00       162\n",
      "          11       1.00      1.00      1.00       169\n",
      "          12       1.00      1.00      1.00       170\n",
      "          13       1.00      1.00      1.00       173\n",
      "          14       1.00      1.00      1.00       162\n",
      "          15       1.00      1.00      1.00       160\n",
      "          16       1.00      1.00      1.00       176\n",
      "\n",
      "    accuracy                           1.00      2754\n",
      "   macro avg       1.00      1.00      1.00      2754\n",
      "weighted avg       1.00      1.00      1.00      2754\n",
      "\n",
      "Confusion Matrix: \n",
      " [[163   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 143   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 170   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 179   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 147   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 167   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 153   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 160   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 142   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0 161   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 173   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 162   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 160   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 176]]\n",
      "==================================================\n",
      "النموذج الثاني (باستخدام البيانات المحجمة فقط):\n",
      "Accuracy:  0.9996368917937546\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       163\n",
      "           1       1.00      1.00      1.00       143\n",
      "           2       1.00      1.00      1.00       170\n",
      "           3       1.00      1.00      1.00       179\n",
      "           4       1.00      1.00      1.00       147\n",
      "           5       1.00      1.00      1.00       167\n",
      "           6       1.00      1.00      1.00       153\n",
      "           7       1.00      1.00      1.00       160\n",
      "           8       0.99      1.00      1.00       158\n",
      "           9       1.00      1.00      1.00       142\n",
      "          10       1.00      0.99      1.00       162\n",
      "          11       1.00      1.00      1.00       169\n",
      "          12       1.00      1.00      1.00       170\n",
      "          13       1.00      1.00      1.00       173\n",
      "          14       1.00      1.00      1.00       162\n",
      "          15       1.00      1.00      1.00       160\n",
      "          16       1.00      1.00      1.00       176\n",
      "\n",
      "    accuracy                           1.00      2754\n",
      "   macro avg       1.00      1.00      1.00      2754\n",
      "weighted avg       1.00      1.00      1.00      2754\n",
      "\n",
      "Confusion Matrix: \n",
      " [[163   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 143   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 170   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0 179   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 147   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 167   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 153   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 160   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 158   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 142   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0 161   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 169   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 170   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 173   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 162   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 160   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 176]]\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 1. تقسيم البيانات\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=150)\n",
    "\n",
    "# 2. تحجيم البيانات\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 3. تدريب النموذج الأول (باستخدام البيانات المحجمة)\n",
    "model_scaled = XGBClassifier(max_depth=5, n_estimators=50, random_state=150)\n",
    "model_scaled.fit(X_train_scaled, y_train)\n",
    "\n",
    "# التنبؤ باستخدام النموذج الأول\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "\n",
    "# تقييم النموذج الأول\n",
    "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
    "print(\"النموذج الأول (باستخدام البيانات المحجمة فقط):\")\n",
    "print(\"Accuracy: \", accuracy_scaled)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_scaled))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_scaled))\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 4. تدريب النموذج الثاني (باستخدام نفس البيانات المحجمة)\n",
    "model_scaled_2 = XGBClassifier(max_depth=5, n_estimators=50, random_state=150)\n",
    "model_scaled_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "# التنبؤ باستخدام النموذج الثاني\n",
    "y_pred_scaled_2 = model_scaled_2.predict(X_test_scaled)\n",
    "\n",
    "# تقييم النموذج الثاني\n",
    "accuracy_scaled_2 = accuracy_score(y_test, y_pred_scaled_2)\n",
    "print(\"النموذج الثاني (باستخدام البيانات المحجمة فقط):\")\n",
    "print(\"Accuracy: \", accuracy_scaled_2)\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_scaled_2))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred_scaled_2))\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c46077fe-4072-4566-8112-691f87f9db6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 15\n",
      "Model Prediction : 15\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 1\n",
    "print(\"Actual Label :\", y_test.iloc[13])\n",
    "print(\"Model Prediction :\",model.predict(X_test_selected[13].reshape(1,-1))[0])\n",
    "if y_test.iloc[13]==model.predict(X_test_selected[13].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "216e95c9-8742-48ff-b812-f402797342cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Label : 5\n",
      "Model Prediction : 5\n",
      "Wow! Model doing well.....\n"
     ]
    }
   ],
   "source": [
    "# test 2\n",
    "print(\"Actual Label :\", y_test.iloc[50])\n",
    "print(\"Model Prediction :\",model.predict(X_test_selected[50].reshape(1,-1))[0])\n",
    "if y_test.iloc[50]==model.predict(X_test_selected[50].reshape(1,-1)):\n",
    "    print(\"Wow! Model doing well.....\")\n",
    "else:\n",
    "    print(\"not sure......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4e4c80b-3b54-4e1e-a0b3-8e65ad8a5c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastapi in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (0.115.8)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: uvicorn in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (0.34.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from fastapi) (0.45.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from fastapi) (2.10.6)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from scikit-learn) (1.9.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from scikit-learn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from starlette<0.46.0,>=0.40.0->fastapi) (4.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\mega2\\anaconda3\\envs\\new\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.46.0,>=0.40.0->fastapi) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "pip install fastapi uvicorn scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6d45319-d2d8-452d-957e-4bfda34de8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "if not os.path.exists('Models'):\n",
    "    os.makedirs('Models')\n",
    "pickle.dump(scaler, open(\"Models/scaler.pkl\", 'wb'))\n",
    "pickle.dump(model, open(\"Models/model.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8736ef30-d709-4315-878c-0d7d3dfce749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [33124]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [33124]\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, Request, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import pickle\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import nest_asyncio  # استيراد nest_asyncio\n",
    "\n",
    "# تحميل النماذج\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "\n",
    "# أسماء الفئات\n",
    "class_names = [\n",
    "    'Database Administrator', 'Hardware Engineer', 'Application Support Engineer', 'Cyber Security Specialist',\n",
    "    'Networking Engineer', 'Software Developer', 'API Specialist', 'Project Manager', 'Information Security Specialist',\n",
    "    'Technical Writer', 'AI ML Specialist', 'Software tester', 'Business Analyst', 'Customer Service Executive',\n",
    "    'Data Scientist', 'Helpdesk Engineer', 'Graphics Designer'\n",
    "]\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "# جلسة لحفظ إجابات المستخدم\n",
    "user_sessions: Dict[str, Dict] = {}\n",
    "\n",
    "# نموذج الإدخال\n",
    "class UserInput(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "# تعيين القيم للإجابات\n",
    "def map_experience(value):\n",
    "    mapping = {\"Excellent\": 3, \"Average\": 2, \"Beginner\": 1, \"Not Interested\": 0}\n",
    "    return mapping.get(value, 0)\n",
    "\n",
    "# قائمة الأسئلة\n",
    "questions = [\n",
    "    \"Database_Fundamentals\",\n",
    "    \"Computer_Architecture\",\n",
    "    \"Leadership_Experience\",\n",
    "    \"Cyber_Security\",\n",
    "    \"Networking\",\n",
    "    \"Software_Development\",\n",
    "    \"Programming_Skills\",\n",
    "    \"Project_Management\",\n",
    "    \"Computer_Forensics_Fundamentals\",\n",
    "    \"Technical_Communication\",\n",
    "    \"AI_ML\",\n",
    "    \"Software_Engineering\",\n",
    "    \"Business_Analysis\",\n",
    "    \"Communication_Skills\",\n",
    "    \"Data_Science\",\n",
    "    \"Troubleshooting_Skills\",\n",
    "    \"Graphics_Designing\"\n",
    "]\n",
    "\n",
    "# صفحة البداية\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return JSONResponse(content={\"message\": \"Welcome to the recommendation API! Use POST /start to begin.\"})\n",
    "\n",
    "# بدء الجلسة\n",
    "@app.post(\"/start\")\n",
    "def start_session(request: Request):\n",
    "    session_id = request.client.host  # استخدام عنوان IP العميل كمعرف للجلسة\n",
    "    user_sessions[session_id] = {\"current_question\": 0, \"answers\": []}\n",
    "    return {\n",
    "        \"message\": \"Session started\",\n",
    "        \"question\": questions[0],\n",
    "        \"options\": [\"Excellent\", \"Average\", \"Beginner\", \"Not Interested\"]  # إضافة الخيارات\n",
    "    }\n",
    "\n",
    "# إجابة المستخدم\n",
    "@app.post(\"/answer\")\n",
    "def answer_question(request: Request, user_input: UserInput):\n",
    "    session_id = request.client.host\n",
    "    if session_id not in user_sessions:\n",
    "        raise HTTPException(status_code=400, detail=\"Session not found. Please start a session first.\")\n",
    "\n",
    "    current_session = user_sessions[session_id]\n",
    "    current_question_index = current_session[\"current_question\"]\n",
    "\n",
    "    # التحقق من صحة الإجابة\n",
    "    if user_input.answer not in [\"Excellent\", \"Average\", \"Beginner\", \"Not Interested\"]:\n",
    "        return {\"error\": \"Invalid answer. Please choose from: Excellent, Average, Beginner, Not Interested.\"}\n",
    "\n",
    "    # حفظ الإجابة\n",
    "    current_session[\"answers\"].append(map_experience(user_input.answer))\n",
    "\n",
    "    # الانتقال إلى السؤال التالي\n",
    "    current_session[\"current_question\"] += 1\n",
    "\n",
    "    if current_session[\"current_question\"] < len(questions):\n",
    "        return {\n",
    "            \"message\": \"Next question\",\n",
    "            \"question\": questions[current_session[\"current_question\"]],\n",
    "            \"options\": [\"Excellent\", \"Average\", \"Beginner\", \"Not Interested\"]  # إضافة الخيارات\n",
    "        }\n",
    "    else:\n",
    "        # إذا تمت الإجابة على جميع الأسئلة\n",
    "        feature_array = np.array([current_session[\"answers\"]])\n",
    "        scaled_features = scaler.transform(feature_array)\n",
    "        probabilities = model.predict_proba(scaled_features)\n",
    "        top_classes_idx = np.argsort(-probabilities[0])[:3]\n",
    "        recommendations = [{\"job\": class_names[idx]} for idx in top_classes_idx]\n",
    "\n",
    "        # حذف الجلسة بعد الانتهاء\n",
    "        del user_sessions[session_id]\n",
    "\n",
    "        return {\"recommendations\": recommendations}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    nest_asyncio.apply()  # تفعيل nest_asyncio\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d81db3-7a87-454c-af9e-933b4044dfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ca747-b32b-4c15-a781-071e7cfffca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c3487-a23c-44b8-bea6-74b51bcd0258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870acae-3814-45a9-ba3f-759c0bc85de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed0f8c-22f2-4a1a-9552-77ac3ae5a16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6db937-5768-4933-984c-f680572855ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fa53c4-9220-469b-8b3b-0bef073a55e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d8535-3a9c-4250-b94b-ad961d85c73f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842b570-cfca-46cf-b726-ee204cd71d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043292c2-1f84-42c5-a69b-03136559ca60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8c249f-acea-4240-9369-ce38a5bd231c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
